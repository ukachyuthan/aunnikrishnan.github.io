<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Achyuthan's Projects</title>
    <style>
        /* Define your custom styles here */
        body {
            background-color: #f2dede; /* Pleasant red background color */
            font-family: Arial, sans-serif;
        }

        header {
            text-align: right;
            padding: 20px;
        }

        header img {
            width: 150px; /* Adjust the image size as needed */
            border-radius: 50%; /* Make the image circular */
        }

        nav {
            background-color: #a94442; /* Red color for the navigation bar */
            padding: 10px;
        }

        nav ul {
            list-style: none;
            padding: 0;
            text-align: center;
        }

        nav ul li {
            display: inline;
            margin-right: 20px;
        }

        nav ul li a {
            text-decoration: none;
            color: #fff; /* White text color for links */
            font-weight: bold;
        }

        main {
            padding: 20px;
        }

        .project {
            margin-bottom: 20px;
            padding: 10px;
            border: 1px solid #ddd;
            background-color: #fff;
            border-radius: 5px;
            display: flex; /* Use Flexbox to control layout */
            flex-direction: column; /* Arrange items in a column */
            align-items: center; /* Center items horizontally within the project box */
            text-align: center; /* Center text within the project box */
            min-width: 500px; /* Adjust the minimum width as needed */
        }

        .project img {
            width: 100%; /* Ensure the image fits the container */
            max-height: 300px; /* Cap the image height */
            object-fit: contain; /* Maintain aspect ratio */
            margin-top: 10px; /* Add some top margin between text and image */
        }

        /* Responsive design for smaller screens */
        @media (max-width: 768px) {
            .project {
                min-width: 100%; /* Ensure project boxes fit smaller screens */
                padding: 15px;
            }
        }

        footer {
            text-align: center;
            padding: 10px;
            background-color: #a94442;
            color: white;
        }
    </style>
</head>
<body>
    <header>
        <!-- Your picture (replace 'your-picture.jpg' with the actual image file) -->
        <img src="1552328526499.jpeg" alt="Your Name">
    </header>
    <nav>
        <ul>
            <li><a href="/" aria-label="Home Page">Home</a></li>
            <li><a href="projects.html" aria-label="Projects Page">Projects</a></li>
            <li><a href="publications.html" aria-label="Publications Page">Publications</a></li>
        </ul>
    </nav>
    <main>
        <!-- List of Projects -->
        <section>
            <h1>My Projects</h1>

            <!-- Project 1 -->
            <article class="project">
                <div>
                    <h3><strong>User-based Optimization of Assistance Availability for Bi-manual Teleoperation</strong></h3>
                    <p>Used the operator's physical workload and control motions to optimize the availability of assistances like scaled motion for precise control and tremor filtering for seamless orientation control of robot arms teleoperated via motion mapping for bi-manual tasks. Compared against other contemporary environment based triggers for assistances this user-based assistance trigger improved teleoperation experience by reducing task completion times by 11% and physical workload by 28%.</p>
                </div>
                <img src="bimual.gif" alt="User-based Optimization Project Image">
            </article>

            <!-- Project 2 -->
            <article class="project">
                <div>
                    <h3><strong>Intuitive and Efficient Control Interfaces for Teleoperation</strong></h3>
                    <p>Developed and compared various teleoperation control interfaces for a mobile bi-manual nursing robot (TRINA). The control interfaces were implemented on a gamepad, Phantom Omni, and Vicon human motion capture system. Object localization for shared autonomy for pick and place was done using a Mask-RCNN object detection system. A user study identified motion mapping interfaces improved operator performance and workload. The studies also identified precise motion and task-specific actions require robot assistance and interface augmentation. The work done in this project helped identify beneficial teleoperation control ideologies that can be extended to other remote manipulation and teleoperation systems.</p>
                </div>
                <img src="project1.png" alt="Control Interfaces Project Image">
            </article>

            <!-- Project 3 -->
            <article class="project">
                <div>
                    <h3><strong>Augmented Reality and Haptic Cues for Remote Manipulation Interfaces</strong></h3>
                    <p>Developed a motion mapping interface for a Kinova Gen3 arm with an HTC Vive VR system. Different levels of autonomy were designed to assist the operator with a pick and place manipulation task to varying degrees. A vibro-tactile haptic interface and AR visual cues to give information about task state, obstacle environment, task success, etc., were also developed for the feedback interface. Identified a dictionary of AR cues that can be used to determine based on the level of autonomy the type of visual interface the participant might likely prefer.</p>
                </div>
                <img src="project2.png" alt="Augmented Reality Project Image">
            </article>

            <!-- Project 4 -->
            <article class="project">
                <div>
                    <h3><strong>Gaze-based Intent Inference and Workload Estimation</strong></h3>
                    <p>Implemented gaze adaptive visual interfaces for manipulation based on gaze motion detected by Tobii Nano screen tracker. A novel cognitive workload index based on gaze motion, gaze allocation, and pupil-based stress inference was developed. Cognitive workload due to stress based on pupil diameter, due to interface complexity identified through gaze motion and workload due to gaze fixations to determine processing workload were implemented to have an online estimation of the operator's cognitive preferences and efforts.</p>
                </div>
                <img src="gaze.png" alt="Gaze-based Intent Inference Project Image">
            </article>

            <!-- Project 5 -->
            <article class="project">
                <div>
                    <h3><strong>Reward Engineering for Autonomous Pick and Place Actions</strong></h3>
                    <p>Implemented an autonomous robot pick and place policy using DDPG with Hindsight Experience Replay in OpenAI gym. Developed several motion and distance-based heuristics for reward engineering with the best reward achieving a 40% improvement in solution convergence compared to the OpenAI baseline. This type of reward engineering methodology can be used to design future models for various tasks that require specialized motions in their autonomous robotic arm motions.</p>
                </div>
                <img src="Results.gif" alt="Reward Engineering Project Image">
            </article>
        </section>
    </main>
    <footer>
        <p>&copy; 2023 Achyuthan Unni Krishnan</p>
    </footer>
</body>
</html>
